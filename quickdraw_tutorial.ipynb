{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "878618cd-dd61-4589-9bbf-937cd70e4c19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras \n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d665812e-e1b6-415d-91f3-258526254b19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (2.10.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from datasets) (0.13.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from datasets) (2023.3.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from datasets) (2.28.2)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from aiohttp->datasets) (3.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from pandas->datasets) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "131bf625",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\texas\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset parquet (C:/Users/texas/.cache/huggingface/datasets/kmewhort___parquet/kmewhort--quickdraw-bins-1pct-sample-eaac784574b05f1b/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 2/2 [00:00<00:00,  7.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset # Hugging face datasets \n",
    "\n",
    "dataset = load_dataset(\"kmewhort/quickdraw-bins-1pct-sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb22100a-242a-4e60-ba17-8b693ca3eefb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'packed_drawing'],\n",
      "        num_rows: 403410\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['label', 'packed_drawing'],\n",
      "        num_rows: 100853\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "from struct import unpack\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7b10107-2f30-4f3a-bd9d-52601420209c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unpack_drawing(file_handle):\n",
    "    key_id, = unpack('Q', file_handle.read(8))\n",
    "    country_code, = unpack('2s', file_handle.read(2))\n",
    "    recognized, = unpack('b', file_handle.read(1))\n",
    "    timestamp, = unpack('I', file_handle.read(4))\n",
    "    n_strokes, = unpack('H', file_handle.read(2))\n",
    "    image = []\n",
    "    n_bytes = 17\n",
    "    for i in range(n_strokes):\n",
    "        n_points, = unpack('H', file_handle.read(2))\n",
    "        fmt = str(n_points) + 'B'\n",
    "        x = unpack(fmt, file_handle.read(n_points))\n",
    "        y = unpack(fmt, file_handle.read(n_points))\n",
    "        image.append((x, y))\n",
    "        n_bytes += 2 + 2*n_points\n",
    "    result = {\n",
    "        'key_id': key_id,\n",
    "        'country_code': country_code,\n",
    "        'recognized': recognized,\n",
    "        'timestamp': timestamp,\n",
    "        'image': image,\n",
    "    }\n",
    "    return result\n",
    "\n",
    "# packed bin -> RGB PIL\n",
    "def binToPIL(packed_drawing):\n",
    "    padding = 8\n",
    "    radius = 7\n",
    "    scale = (224.0-(2*padding)) / 256\n",
    "    \n",
    "    unpacked = unpack_drawing(io.BytesIO(packed_drawing))\n",
    "    unpacked_image = unpacked['image']\n",
    "    image = np.full((224,224), 255, np.uint8)\n",
    "    for stroke in unpacked['image']:\n",
    "        prevX = round(stroke[0][0]*scale)\n",
    "        prevY = round(stroke[1][0]*scale)\n",
    "        for i in range(1, len(stroke[0])):\n",
    "            x = round(stroke[0][i]*scale)\n",
    "            y = round(stroke[1][i]*scale)\n",
    "            cv2.line(image, (padding+prevX, padding+prevY), (padding+x, padding+y), 0, radius, -1)\n",
    "            prevX = x\n",
    "            prevY = y\n",
    "    # turn image into 28 x 28\n",
    "    image = cv2.resize(image, (28, 28))\n",
    "    return image\n",
    "    pilImage = Image.fromarray(image).convert(\"RGB\")     \n",
    "    return pilImage\n",
    "\n",
    "\n",
    "# unpack_drawing(dataset['train'][0]['features']['packed_drawing'])\n",
    "# unpack_drawing(io.BytesIO(dataset['train'][0]['packed_drawing']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "161bead8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(403410,)\n"
     ]
    }
   ],
   "source": [
    "# x_train = np.array([str(dataset['train'][i]['packed_drawing']) for i in range(len(dataset['train']))])\n",
    "x_temp = np.array([dataset['train'][i]['packed_drawing'] for i in range(len(dataset['train']))])\n",
    "y_temp = np.array([dataset['train'][i]['label'] for i in range(len(dataset['train']))])\n",
    "\n",
    "print(x_temp.shape)\n",
    "\n",
    "# randomize the data\n",
    "p = np.random.permutation(len(x_temp))\n",
    "x_temp = x_temp[p]\n",
    "y_temp = y_temp[p]\n",
    "\n",
    "# only use a thousand samples for now\n",
    "# x_temp = x_temp[:10000]\n",
    "# y_temp = y_temp[:10000]\n",
    "\n",
    "# testing temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42a18bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20422\n"
     ]
    }
   ],
   "source": [
    "# bin to PIL\n",
    "# binToPIL(str(x_train[35]))\n",
    "x = []\n",
    "y = []\n",
    "counter = 0\n",
    "for i in range(len(x_temp)):\n",
    "    try:\n",
    "        x.append(binToPIL(x_temp[i]))\n",
    "        y.append(y_temp[i])\n",
    "    except:\n",
    "        counter += 1\n",
    "        # print(x_temp[i])\n",
    "\n",
    "print(counter)\n",
    "# to numpy array\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "# split into train and test\n",
    "split = 0.8\n",
    "x_train = x[:int(split * len(x))]\n",
    "y_train = y[:int(split * len(y))]\n",
    "x_test = x[int(split * len(x)) :]\n",
    "y_test = y[int(split * len(y)) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1274996",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
    "\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59d614c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the fly byte tensor to np array layer\n",
    "class ByteTensorToNumpyArray(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ByteTensorToNumpyArray, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.numpy_function(func=binToPIL, inp=[inputs], Tout=tf.uint8)\n",
    "    \n",
    "layer = ByteTensorToNumpyArray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4900950b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 14, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 7, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 3, 3, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               73856     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 345)               44505     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 141,657\n",
      "Trainable params: 141,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Convert class vectors to class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, 345)\n",
    "y_test = keras.utils.to_categorical(y_test, 345)\n",
    "\n",
    "model = keras.Sequential()\n",
    "# model.add(layer)\n",
    "model.add(layers.Convolution2D(16, (3, 3),\n",
    "                        padding='same',\n",
    "                        input_shape=x_train.shape[1:], activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Convolution2D(32, (3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Convolution2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(345, activation='softmax'))\n",
    "# Train model\n",
    "# adam = tf.train.AdamOptimizer()\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=adam,\n",
    "#               metrics=['top_k_categorical_accuracy'])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['top_k_categorical_accuracy'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa73cabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1078/1078 - 123s - loss: 3.9183 - top_k_categorical_accuracy: 0.4198 - val_loss: 3.0289 - val_top_k_categorical_accuracy: 0.6127 - 123s/epoch - 114ms/step\n",
      "Epoch 2/5\n",
      "1078/1078 - 113s - loss: 2.7879 - top_k_categorical_accuracy: 0.6579 - val_loss: 2.6630 - val_top_k_categorical_accuracy: 0.6787 - 113s/epoch - 104ms/step\n",
      "Epoch 3/5\n",
      "1078/1078 - 107s - loss: 2.4948 - top_k_categorical_accuracy: 0.7106 - val_loss: 2.4869 - val_top_k_categorical_accuracy: 0.7148 - 107s/epoch - 99ms/step\n",
      "Epoch 4/5\n",
      "1078/1078 - 144s - loss: 2.3324 - top_k_categorical_accuracy: 0.7381 - val_loss: 2.3637 - val_top_k_categorical_accuracy: 0.7370 - 144s/epoch - 134ms/step\n",
      "Epoch 5/5\n",
      "1078/1078 - 137s - loss: 2.2286 - top_k_categorical_accuracy: 0.7558 - val_loss: 2.2919 - val_top_k_categorical_accuracy: 0.7486 - 137s/epoch - 127ms/step\n",
      "Test accuarcy: 74.94%\n"
     ]
    }
   ],
   "source": [
    "model.fit(x = x_train, y = y_train, validation_split=0.1, batch_size = 256, verbose=2, epochs=5)\n",
    "\n",
    "#evaluate on unseen data\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
